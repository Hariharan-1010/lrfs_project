import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
import seaborn as sns
import pickle

# Define the DataPipeline and model as provided
class DataPipeline:
    def __init__(self):
        self.month_encoder_dict = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'June': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}
        with open('le_vt.pkl', 'rb') as le_file:
            self.le_vt = pickle.load(le_file)
        with open('le_r.pkl', 'rb') as le_file:
            self.le_r = pickle.load(le_file)
        with open('l_ss.pkl', 'rb') as le_file:
            self.l_ss = pickle.load(le_file)
        with open('r_ss.pkl', 'rb') as le_file:
            self.r_ss = pickle.load(le_file)
        with open('f_ss.pkl', 'rb') as le_file:
            self.f_ss = pickle.load(le_file)
        with open('s_ss.pkl', 'rb') as le_file:
            self.s_ss = pickle.load(le_file)

    def calculate_length(self, row):
        if row['VisitorType'] == 2:  # Returning customer
            return row['Month'] - 1
        else:  # New customer
            return 1

    def data_pipeline(self, input_data):
        df = input_data.copy()
        df.dropna(inplace=True)
        df.drop_duplicates(inplace=True)

        df['Month'] = df['Month'].map(self.month_encoder_dict)
        df['VisitorType'] = self.le_vt.transform(df['VisitorType'])
        df['Revenue'] = self.le_r.transform(df['Revenue'])

        l = df.apply(self.calculate_length, axis=1)
        r = 12 - df['Month'] + 1
        f = df['Administrative'] + df['Informational'] + df['ProductRelated']
        s = df['PageValues'] * (1 - df['ExitRates'])

        ret_df = {'L': l, 'R': r, 'F': f, 'S': s, 'Revenue': df['Revenue']}
        ret_df = pd.DataFrame(ret_df)

        ret_df['L'] = self.l_ss.transform(ret_df['L'].values.reshape(-1, 1))
        ret_df['R'] = self.r_ss.transform(ret_df['R'].values.reshape(-1, 1))
        ret_df['F'] = self.f_ss.transform(ret_df['F'].values.reshape(-1, 1))
        ret_df['S'] = self.s_ss.transform(ret_df['S'].values.reshape(-1, 1))

        return ret_df

# Load the model
clf = pickle.load(open('lrfs_model.sav', 'rb'))

data_pipeline = DataPipeline()

# Streamlit App
st.title("ðŸŽˆ LRFS Customer Segmentation")
tabs = st.tabs(["Home", "Score", "Pred"])

# Home Tab
with tabs[0]:  # Home Tab
    st.header("Welcome to the LRFS Model for Customer Segmentation")

    # Abstract Section
    st.subheader("Abstract")
    st.write("""
    In the realm of digital commerce, online shopping has witnessed unprecedented growth
globally, becoming a cornerstone of modern consumer behavior. This research introduces an advanced
customer segmentation model, named LRFS, which builds upon the traditional LRF framework (Length
of Relationship, Recency of Purchase, and Frequency of Purchase), specifically tailored for the e-commerce
sector. The innovation of the LRFS model lies in the integration of a novel component, "S", which quantifies
the Staying Rate relative to the revenue generated by customers on a specific website. This addition aims
to enhance the granularity and efficacy of customer segmentation by leveraging data extracted from Google
Analytics.Through
the development and application of the LRFS model, this study contributes significantly to the field of
e-commerce by providing a more nuanced tool for businesses to tailor their marketing initiatives, ensuring
alignment with the evolving preferences and behaviors of their online clientele.

    """)

    # Features Section
    st.subheader("Features Used")
    st.write("""
    Below are the features utilized in this research, along with their descriptions and formats:
    """)

    st.markdown("""
    - **VisitorType**: Categorizes users based on their relationship with the website.  
      - Format: Categorical (`New_Visitor`, `Returning_Visitor`).
    - **Month**: Represents the month in which user activity is recorded.  
      - Format: Categorical (`Jan`, `Feb`, ..., `Dec`).
    - **Administrative**: The number of administrative pages the user visited.  
      - Format: Integer.
    - **Informational**: The number of informational pages the user visited.  
      - Format: Integer.
    - **ProductRelated**: The number of product-related pages the user visited.  
      - Format: Integer.
    - **PageValues**: Represents the value of the pages visited, based on their contribution to revenue.  
      - Format: Float.
    - **ExitRates**: Indicates the rate at which users exit the website from a given page.  
      - Format: Float (range: 0 to 1).
    """)

    # L, R, F, S Section
    st.subheader("How L, R, F, and S Are Extracted")
    st.write("""
    Hereâ€™s a breakdown of how the Length (L), Recency (R), Frequency (F), and Staying Rate (S) metrics are calculated:
    """)

    st.markdown("""
    - **Length (L)**:  
      - Measures the duration of the userâ€™s relationship with the website.  
      - Calculation: For new visitors (`VisitorType == New_Visitor`), the value is `1`.  
        For returning visitors, itâ€™s `Month - 1`.

    - **Recency (R)**:  
      - Captures how recently the user engaged with the website.  
      - Calculation: `12 - Month + 1`.

    - **Frequency (F)**:  
      - Summarizes the total number of pages visited by the user.  
      - Calculation: `Administrative + Informational + ProductRelated`.

    - **Staying Rate (S)**:  
      - Quantifies the engagement of users in relation to the revenue generated.  
      - Calculation: `PageValues * (1 - ExitRates)`.
    """)

    # Applications Section
    st.subheader("BTS of the LRFS Model")
    st.write("""
    These features, after preprocessing, are used to construct the LRFS model.
The extracted metrics (L, R, F, S) undergo standardization before being fed into the classfication algorithms (e.g., SVM, KNN, Random Forest, Gradient Boosting Classifier).
             Predictions are made by using Voting Classifier
    """)

    # Footer
    st.write("""
    This project introduces a sophisticated approach to customer segmentation, enhancing marketing strategies and
    fostering a deeper understanding of online customer behavior.
             
    Training Dataset URL: https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset

    References: Real-time prediction of online shoppers' purchasing intention using multilayer perceptron and LSTM recurrent neural networks
By C. O. Sakar, S. Polat, Mete Katircioglu, Yomi Kastro. 2019
Published in Neural computing & applications (Print)

    """)


# Score Tab
with tabs[1]:
    st.header("Score")
    uploaded_file = st.file_uploader("Upload CSV file for scoring", type="csv")

    if uploaded_file is not None:
        try:
            input_data = pd.read_csv(uploaded_file)
            processed_data = data_pipeline.data_pipeline(input_data)
            scores = clf.predict(processed_data.drop(columns=['Revenue']))
            actual = processed_data['Revenue']

            st.write("### Scored Data")
            processed_data['Scores'] = scores
            st.write(processed_data)

            # Metrics and Confusion Matrix
            st.write("### Classification Metrics")
            st.write("Accuracy:", (scores == actual).mean())

            st.write("### Confusion Matrix")
            cm = confusion_matrix(actual, scores)
            fig, ax = plt.subplots()
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
            ax.set_title("Confusion Matrix")
            ax.set_xlabel("Predicted")
            ax.set_ylabel("Actual")
            st.pyplot(fig)

            # Classification Report
            st.write("### Detailed Report")
            report = classification_report(actual, scores, output_dict=True)
            st.write(pd.DataFrame(report).transpose())

            # ROC Curve
            st.write("### ROC Curve")
            fpr, tpr, _ = roc_curve(actual, scores)
            roc_auc = auc(fpr, tpr)
            fig, ax = plt.subplots()
            ax.plot(fpr, tpr, label=f"ROC Curve (AUC = {roc_auc:.2f})")
            ax.plot([0, 1], [0, 1], 'k--', label="Random Guess")
            ax.set_title("ROC Curve")
            ax.set_xlabel("False Positive Rate")
            ax.set_ylabel("True Positive Rate")
            ax.legend()
            st.pyplot(fig)

        except Exception as e:
            st.error(f"Error processing file: {e}")

with tabs[2]:
    st.header("Predict")
    st.write("### Input data for prediction")
    visitor_type = st.selectbox("Visitor Type", ["New_Visitor", "Returning_Visitor"])
    month = st.selectbox("Month", list(data_pipeline.month_encoder_dict.keys()))
    admin = st.text_input("Administrative", value="0")
    info = st.text_input("Informational", value="0")
    product_related = st.text_input("Product Related", value="0")
    page_values = st.text_input("Page Values", value="0.0")
    exit_rates = st.text_input("Exit Rates", value="0.0")

    if st.button("Predict"):
        try:
            # Ensure input values are correctly formatted
            input_data = pd.DataFrame({
                'VisitorType': [visitor_type],
                'Month': [month],
                'Administrative': [int(admin)],
                'Informational': [int(info)],
                'ProductRelated': [int(product_related)],
                'PageValues': [float(page_values)],
                'ExitRates': [float(exit_rates)],
                'Revenue': [0]
            })

            # Process input data
            processed_data = data_pipeline.data_pipeline(input_data)

            features = processed_data.drop(columns=['Revenue'])
            prediction = clf.predict(features)[0]

            st.success(f"Prediction: {'Revenue Generated' if prediction == 1 else 'No Revenue Generated'}")
        except Exception as e:
            st.error(f"Error making prediction: {e}")
